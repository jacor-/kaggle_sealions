{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exec(compile(open(\"fix_paths.py\", \"rb\").read(), \"fix_paths.py\", 'exec'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from common import dataset_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_category = {0:'sealion', 1:'sealion', 2:'sealion', 3:'sealion', 4:'sealion'}\n",
    "\n",
    "original_labels = dataset_loaders.groundlabels_dataframe()\n",
    "now_labels = dataset_loaders.map_labels(original_labels, map_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_case = dataset_loaders.get_casenames()\n",
    "casename = train_case[0]\n",
    "data = dataset_loaders.load_image(casename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: libcublas.so.8.0: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import scipy.misc\n",
    "from common import dataset_loaders\n",
    "\n",
    "\n",
    "\n",
    "# We generate a label ready for multiclass based on the string labels we use as input\n",
    "class LabelEncoding(object):\n",
    "\n",
    "    def __init__(self, input_classes):\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(input_classes)\n",
    "        encoded_Y = encoder.transform(input_classes)\n",
    "        lb = LabelBinarizer()\n",
    "        lb.fit_transform(encoded_Y)\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.lb = lb\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return self.lb.transform(self.encoder.transform(x))\n",
    "    \n",
    "    def get_class_id(self, label, binarized = True):\n",
    "        if type(label) == np.ndarray:\n",
    "            label = self.lb.classes_[np.argmax(label)]\n",
    "        label = self.encoder.classes_[label]\n",
    "        return label \n",
    "    \n",
    "\n",
    "# We generate patches a punta pala\n",
    "def _get_positive_patches_from_image(img, case, df, patch_size):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for ind in df[df['image'] == case].index:\n",
    "        row = df.ix[ind]\n",
    "        label, x, y = row['class'], row['x'], row['y']\n",
    "        if  x - int(patch_size/2) >= 0 and x + int(patch_size/2) < img.shape[0] and y - int(patch_size/2) >= 0 and y + int(patch_size/2) < img.shape[1]:\n",
    "            X.append(img[x-int(patch_size/2):x+int(patch_size/2), y-int(patch_size/2):y+int(patch_size/2),:])\n",
    "            Y.append(label)\n",
    "    return np.asarray(X, dtype = 'float32'), np.array(Y)\n",
    "    \n",
    "def _get_negative_patches_from_image(img, case, df, patch_size, quant_patches, label_to_use):\n",
    "    car_coordinates = np.array(df[df['image'] == case][['x','y']].values)\n",
    "\n",
    "    all_coords = []\n",
    "    while len(all_coords) < quant_patches:\n",
    "        new_coord = np.random.randint(2000-patch_size, size = [2]) + patch_size/2\n",
    "        # we are far from all the other car coordinates\n",
    "        if car_coordinates.shape[0] > 0:\n",
    "            # BE CAREFUL!!! We divide by 3 to get some patches where there is a car, but not centered in the picture.\n",
    "            # We want the network to be able to be able to distinguish location\n",
    "            if (np.abs(car_coordinates - new_coord) > patch_size / 3).max(axis=1).all(): \n",
    "                all_coords.append(new_coord)\n",
    "        else:\n",
    "            all_coords.append(new_coord)\n",
    "    patches = []\n",
    "    for x,y in all_coords:\n",
    "        patches.append(img[int(x-patch_size/2):int(x+patch_size / 2),int(y-patch_size/2):int(y+patch_size / 2),:])\n",
    "\n",
    "    return np.asarray(patches, dtype = 'float32'), np.array([label_to_use for i in range(len(patches))])\n",
    "\n",
    "def generatePatches_from_image(imagename, df, patch_size, quant_negative_patches = 25, negative_patch_label = 'background'):\n",
    "    img = dataset_loaders.load_image(imagename)\n",
    "    X_pos, Y_pos = _get_positive_patches_from_image(img, imagename, df, patch_size)\n",
    "    X_neg, Y_neg = _get_negative_patches_from_image(img, imagename, df, patch_size, quant_negative_patches, negative_patch_label)\n",
    "    del img\n",
    "    if len(Y_pos) == 0:\n",
    "        return X_neg, Y_neg\n",
    "    else:\n",
    "        return np.vstack([X_pos, X_neg]), np.concatenate([Y_pos, Y_neg])\n",
    "\n",
    "def generate_chunks(df, batch_size, patch_size, min_buffer_before_start = 250, neg_patches = 25):\n",
    "    buffer_X = []\n",
    "    buffer_Y = []\n",
    "    while(1):\n",
    "        imagename = df['image'].ix[np.random.randint(df.shape[0])]\n",
    "        X, Y = generatePatches_from_image(imagename, df, patch_size, quant_negative_patches = neg_patches, negative_patch_label = 'background')\n",
    "        if len(buffer_X) == 0:\n",
    "            buffer_X, buffer_Y = X, Y\n",
    "        else:\n",
    "            buffer_X = np.vstack([X, buffer_X])\n",
    "            buffer_Y = np.concatenate([Y, buffer_Y])\n",
    "        \n",
    "        if len(buffer_X) > min_buffer_before_start:\n",
    "            # Start sending!\n",
    "            indexs = np.array(range(len(buffer_X)))\n",
    "            np.random.shuffle(indexs)\n",
    "            buffer_X, buffer_Y = buffer_X[indexs], buffer_Y[indexs]\n",
    "            yield buffer_X[:batch_size], buffer_Y[:batch_size]\n",
    "            buffer_X, buffer_Y = buffer_X[batch_size:], buffer_Y[batch_size:]\n",
    "\n",
    "\n",
    "def data_generator(dataaugmentation, labelencoder, df, batch_size, patch_size, min_buffer_before_start = 200, neg_patches = 15, image_size_nn = 48):\n",
    "    for x, y in generate_chunks(df, batch_size, patch_size, min_buffer_before_start, neg_patches):\n",
    "        if dataaugmentation is not None:\n",
    "            for x, y in dataaugmentation.flow(x, y, batch_size = batch_size, shuffle = False):\n",
    "                break\n",
    "        ## TODO If I want to do many rescales, here is the point!\n",
    "        x = np.array([scipy.misc.imresize(ss, [image_size_nn, image_size_nn]) / 255 for ss in x])\n",
    "        yield x.transpose([0,3,1,2]), labelencoder.encode(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['background'] + list(now_labels['class'].unique())\n",
    "\n",
    "dataaugmentation = None\n",
    "labelencoder= LabelEncoding(classes)\n",
    "df = now_labels\n",
    "batch_size = 150\n",
    "patch_size = 80\n",
    "min_buffer_before_start = batch_size\n",
    "neg_patches = 15\n",
    "image_size_nn = patch_size\n",
    "\n",
    "generator = data_generator(dataaugmentation, labelencoder, df, batch_size, patch_size, min_buffer_before_start = min_buffer_before_start, neg_patches = neg_patches, image_size_nn = image_size_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/tech/anaconda3/envs/kgsealions/lib/python3.6/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['power', 'linalg', 'fft', 'random', 'info']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 3, 80, 80) (150, 1) 138\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 143\n",
      "(150, 3, 80, 80) (150, 1) 141\n",
      "(150, 3, 80, 80) (150, 1) 142\n",
      "(150, 3, 80, 80) (150, 1) 139\n",
      "(150, 3, 80, 80) (150, 1) 138\n",
      "(150, 3, 80, 80) (150, 1) 142\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 141\n",
      "(150, 3, 80, 80) (150, 1) 146\n",
      "(150, 3, 80, 80) (150, 1) 140\n",
      "(150, 3, 80, 80) (150, 1) 140\n",
      "(150, 3, 80, 80) (150, 1) 141\n",
      "(150, 3, 80, 80) (150, 1) 145\n",
      "(150, 3, 80, 80) (150, 1) 138\n",
      "(150, 3, 80, 80) (150, 1) 146\n",
      "(150, 3, 80, 80) (150, 1) 145\n",
      "(150, 3, 80, 80) (150, 1) 140\n",
      "(150, 3, 80, 80) (150, 1) 137\n",
      "(150, 3, 80, 80) (150, 1) 141\n",
      "(150, 3, 80, 80) (150, 1) 140\n",
      "(150, 3, 80, 80) (150, 1) 139\n",
      "(150, 3, 80, 80) (150, 1) 138\n",
      "(150, 3, 80, 80) (150, 1) 140\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 142\n",
      "(150, 3, 80, 80) (150, 1) 145\n",
      "(150, 3, 80, 80) (150, 1) 142\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 143\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 146\n",
      "(150, 3, 80, 80) (150, 1) 145\n",
      "(150, 3, 80, 80) (150, 1) 140\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 142\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 148\n",
      "(150, 3, 80, 80) (150, 1) 146\n",
      "(150, 3, 80, 80) (150, 1) 141\n",
      "(150, 3, 80, 80) (150, 1) 143\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 146\n",
      "(150, 3, 80, 80) (150, 1) 149\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 143\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 140\n",
      "(150, 3, 80, 80) (150, 1) 146\n",
      "(150, 3, 80, 80) (150, 1) 143\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 142\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 144\n",
      "(150, 3, 80, 80) (150, 1) 149\n",
      "(150, 3, 80, 80) (150, 1) 142\n",
      "(150, 3, 80, 80) (150, 1) 146\n"
     ]
    }
   ],
   "source": [
    "from pylab import *\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15, 15)\n",
    "\n",
    "from common import plot_utils\n",
    "counting = 0\n",
    "for x, y in generator:\n",
    "    #plot_utils.multidraw([10,4], x.transpose([0,2,3,1]))    \n",
    "    print(x.shape, y.shape, y.sum())\n",
    "    counting += 1\n",
    "    if counting == 100:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Virtulenv_Python_3_kgsealions",
   "language": "python",
   "name": "virtulenv_python_3_kgsealions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
