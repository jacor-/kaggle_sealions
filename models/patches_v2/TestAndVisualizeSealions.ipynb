{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exec(compile(open(\"fix_paths.py\", \"rb\").read(), \"fix_paths.py\", 'exec'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: libcublas.so.8.0: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n## train_data = pd.read_csv(\\'%s/%s/train_df.csv\\' % (settings.DATAMODEL_PATH, experiment_folder_name))\\n## valid_data = pd.read_csv(\\'%s/%s/valid_df.csv\\' % (settings.DATAMODEL_PATH, experiment_folder_name))\\n\\n# Initialize these cases\\n## We add background as label to the rest of existing labels\\nexisting_labels = np.concatenate([original_labels[\\'class\\'].unique(), [\\'background\\']])\\nlabelencoder = LabelEncoding(existing_labels)\\n\\n\\n########################################################\\n### Load model\\n########################################################\\nmodel = ResnetBuilder().build_resnet_50((3,image_size_nn,image_size_nn),len(existing_labels))\\nmodel.compile(optimizer=Adam(lr=1e-4), loss=\\'categorical_crossentropy\\')#,\\'fmeasure\\'])\\nmodel.load_weights(OUTPUT_MODEL)\\n\\n\\n\\n########################################################\\n### Run predictons\\n########################################################\\n\\ndef predict_case(case):\\n    t1 = time.time()\\n    img = dataset_loaders.load_image(case)\\n    patches = scan_patches(img, image_size_nn, patch_size, scan_step, batch_size, square_to_scan = None)\\n    preds = []\\n    for x in patches:\\n        preds.append(model.predict(x))\\n    preds = np.vstack(preds)\\n    \\n    # Reshape the image to the original shape, so we can map predictions to actual locations\\n    siz1 =  int((img.shape[0]-patch_size)/scan_step)+1\\n    siz2 =  int((img.shape[1]-patch_size)/scan_step)+1\\n\\n    preds = preds.reshape([siz1,siz2,preds.shape[1]])\\n    return preds, time.time()-t1\\n\\n\\n#for casename in dataset_loaders.get_casenames():\\n#    filename_to_save = annotations_name.format(path=ANNOTATIONS_PATH,scan_window=scan_step, casename=casename)\\n#    if not os.path.isfile(filename_to_save):\\n#        print(\"- Startin case %s with window step %d\" % (casename, scan_step))\\n#        preds, takentime = predict_case(casename)\\n#        print(\"- Calculated case %s with window step %d in %0.0f seconds\" % (casename, scan_step, takentime))\\n#        np.savez_compressed(filename_to_save, preds = preds)\\n#    else:\\n#        print(\"- [ALREADY DONE] %s\" % filename_to_save)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# This line solves some minor problems when you do not have propery set the PYTHONPATH\n",
    "exec(compile(open(\"fix_paths.py\", \"rb\").read(), \"fix_paths.py\", 'exec'))\n",
    "\n",
    "#import tensorflow as tf \n",
    "#import keras\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "#config.gpu_options.allow_growth = True\n",
    "#set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "import settings\n",
    "import os\n",
    "import pandas as pd\n",
    "from common import dataset_loaders\n",
    "from patch_generators.pos_and_negative_fix_size import LabelEncoding\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import logging\n",
    "from sklearn import metrics\n",
    "from keras import backend as K\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback, History\n",
    "from dl_utils.dl_networks.resnet import ResnetBuilder\n",
    "\n",
    "import scipy.misc\n",
    "\n",
    "\n",
    "########################################################\n",
    "### Parameters\n",
    "########################################################\n",
    "experiment_folder_name = 'patch_seal_finder'\n",
    "experiment_name = 'resnet_v0'\n",
    "annotations_name = '{path}/sfinder_{casename}_{scan_window}.npz'\n",
    "OUTPUT_MODEL = '%s/%s/models/seal_finder_remote.hdf5' % (settings.DATAMODEL_PATH, experiment_folder_name)\n",
    "\n",
    "image_size_nn = 50\n",
    "patch_size = 80\n",
    "\n",
    "batch_size = 2500\n",
    "scan_step = 20\n",
    "\n",
    "########################################################\n",
    "### Parameters\n",
    "########################################################\n",
    "LOGS_PATH    = '%s/%s/logs/%s' % (settings.DATAMODEL_PATH, experiment_folder_name, experiment_name)\n",
    "ANNOTATIONS_PATH = '%s/%s/annotations' % (settings.DATAMODEL_PATH, experiment_folder_name)\n",
    "os.system('mkdir -p %s' % (ANNOTATIONS_PATH))\n",
    "\n",
    "########################################################\n",
    "### Function to load patches\n",
    "########################################################\n",
    "def scan_patches(img, image_size_nn, patch_size, step_frames, batch_size, square_to_scan = None):\n",
    "    if square_to_scan is None:\n",
    "        square_to_scan = [0,img.shape[0],0,img.shape[1]]\n",
    "    # Ensure the patch does not go out of the image\n",
    "    x_ini = np.max([square_to_scan[0], int(patch_size/2)])\n",
    "    x_end = np.min([square_to_scan[1], int(img.shape[0]-patch_size/2)])\n",
    "    y_ini = np.max([square_to_scan[2], int(patch_size/2)])\n",
    "    y_end = np.min([square_to_scan[3], int(img.shape[1]-patch_size/2)])\n",
    "    \n",
    "    patches = []\n",
    "    wnd = int(patch_size/2)\n",
    "    for xi in range(x_ini, x_end, step_frames):\n",
    "        for yi in range(y_ini, y_end, step_frames):\n",
    "            patches.append(scipy.misc.imresize(img[xi-wnd:xi+wnd,yi-wnd:yi+wnd], [image_size_nn, image_size_nn]) / 255)\n",
    "            if len(patches) == batch_size:\n",
    "                #print(xi,yi, \"  out of \", x_ini, x_end, y_ini, y_end)\n",
    "                yield np.array(patches).transpose([0,3,1,2])\n",
    "                patches = []\n",
    "    if len(patches) > 0:\n",
    "        print(xi,yi, \"  out of \", x_ini, x_end, y_ini, y_end)\n",
    "        yield np.array(patches).transpose([0,3,1,2])\n",
    "\n",
    "\n",
    "########################################################\n",
    "### Initilize things\n",
    "########################################################\n",
    "\n",
    "# We load the cases as they were originally...if needed\n",
    "map_category = {0:'sealion',1:'sealion',2:'sealion',3:'sealion',4:'sealion'}\n",
    "original_labels = dataset_loaders.groundlabels_dataframe()\n",
    "original_labels = dataset_loaders.map_labels(original_labels, map_category)\n",
    "'''\n",
    "## train_data = pd.read_csv('%s/%s/train_df.csv' % (settings.DATAMODEL_PATH, experiment_folder_name))\n",
    "## valid_data = pd.read_csv('%s/%s/valid_df.csv' % (settings.DATAMODEL_PATH, experiment_folder_name))\n",
    "\n",
    "# Initialize these cases\n",
    "## We add background as label to the rest of existing labels\n",
    "existing_labels = np.concatenate([original_labels['class'].unique(), ['background']])\n",
    "labelencoder = LabelEncoding(existing_labels)\n",
    "\n",
    "\n",
    "########################################################\n",
    "### Load model\n",
    "########################################################\n",
    "model = ResnetBuilder().build_resnet_50((3,image_size_nn,image_size_nn),len(existing_labels))\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy')#,'fmeasure'])\n",
    "model.load_weights(OUTPUT_MODEL)\n",
    "\n",
    "\n",
    "\n",
    "########################################################\n",
    "### Run predictons\n",
    "########################################################\n",
    "\n",
    "def predict_case(case):\n",
    "    t1 = time.time()\n",
    "    img = dataset_loaders.load_image(case)\n",
    "    patches = scan_patches(img, image_size_nn, patch_size, scan_step, batch_size, square_to_scan = None)\n",
    "    preds = []\n",
    "    for x in patches:\n",
    "        preds.append(model.predict(x))\n",
    "    preds = np.vstack(preds)\n",
    "    \n",
    "    # Reshape the image to the original shape, so we can map predictions to actual locations\n",
    "    siz1 =  int((img.shape[0]-patch_size)/scan_step)+1\n",
    "    siz2 =  int((img.shape[1]-patch_size)/scan_step)+1\n",
    "\n",
    "    preds = preds.reshape([siz1,siz2,preds.shape[1]])\n",
    "    return preds, time.time()-t1\n",
    "\n",
    "\n",
    "#for casename in dataset_loaders.get_casenames():\n",
    "#    filename_to_save = annotations_name.format(path=ANNOTATIONS_PATH,scan_window=scan_step, casename=casename)\n",
    "#    if not os.path.isfile(filename_to_save):\n",
    "#        print(\"- Startin case %s with window step %d\" % (casename, scan_step))\n",
    "#        preds, takentime = predict_case(casename)\n",
    "#        print(\"- Calculated case %s with window step %d in %0.0f seconds\" % (casename, scan_step, takentime))\n",
    "#        np.savez_compressed(filename_to_save, preds = preds)\n",
    "#    else:\n",
    "#        print(\"- [ALREADY DONE] %s\" % filename_to_save)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a2e321bda6be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m#for case_to_plot in range(len(annotated_files)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcase_to_plot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'616'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mplot_cae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcase_to_plot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Case \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotated_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcase_to_plot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# saves the current figure into a pdf page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-a2e321bda6be>\u001b[0m in \u001b[0;36mplot_cae\u001b[0;34m(case_to_plot)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_cae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcase_to_plot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mfile_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotated_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcase_to_plot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mcaseid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_loaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaseid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "exec(compile(open(\"fix_paths.py\", \"rb\").read(), \"fix_paths.py\", 'exec'))  \n",
    "import settings\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "import pylab\n",
    "\n",
    "########################################################\n",
    "### Parameters\n",
    "########################################################\n",
    "experiment_folder_name = 'patch_seal_finder'\n",
    "experiment_name = 'resnet_v0'\n",
    "OUTPUT_MODEL = '%s/%s/models/seal_finder_remote.hdf5' % (settings.DATAMODEL_PATH, experiment_folder_name)\n",
    "\n",
    "image_size_nn = 50\n",
    "patch_size = 80\n",
    "\n",
    "batch_size = 2500\n",
    "scan_step = 20\n",
    "\n",
    "########################################################\n",
    "### Parameters\n",
    "########################################################\n",
    "ANNOTATIONS_PATH = '%s/%s/annotations' % (settings.DATAMODEL_PATH, experiment_folder_name)\n",
    "\n",
    "########################################################\n",
    "### Initilize things\n",
    "########################################################\n",
    "\n",
    "# We load the cases as they were originally...if needed\n",
    "map_category = {0:'sealion',1:'sealion',2:'sealion',3:'sealion',4:'sealion'}\n",
    "original_labels = dataset_loaders.groundlabels_dataframe()\n",
    "original_labels = dataset_loaders.map_labels(original_labels, map_category)\n",
    "\n",
    "\n",
    "########################################################\n",
    "### Run predictions and save file\n",
    "########################################################\n",
    "\n",
    "annotated_files = os.listdir(ANNOTATIONS_PATH)\n",
    "\n",
    "\n",
    "def plot_cae(case_to_plot):\n",
    "    file_id = annotated_files[case_to_plot]\n",
    "    caseid = file_id.split(\"_\")[1]\n",
    "    img = dataset_loaders.load_image(caseid)\n",
    "    detection = np.load(ANNOTATIONS_PATH+'/'+file_id)['preds']\n",
    "    labels = original_labels[original_labels.image == int(caseid)]\n",
    "\n",
    "\n",
    "    figure()\n",
    "    title(\"EIS!\")\n",
    "    subplot(121)\n",
    "    imshow(detection[:,:,0])\n",
    "    plot((labels.y-patch_size/2)/scan_step,(labels.x-patch_size/2)/scan_step,'xr')\n",
    "    subplot(122)\n",
    "    imshow(img)\n",
    "    plot(labels.y,labels.x,'xr')\n",
    "    print(\"My first stage prediction and groundtruth for case \" + str(caseid))\n",
    "    \n",
    "\n",
    "\n",
    "with PdfPages('output_pdf_' + OUTPUT_MODEL.split(\"/\")[-1].split(\".\")[0] + '.pdf') as pdf:\n",
    "    \n",
    "    for case_to_plot in range(len(annotated_files)):\n",
    "        plot_cae(case_to_plot)\n",
    "        suptitle(\"Case \" + str(annotated_files[case_to_plot]))\n",
    "        pdf.savefig()  # saves the current figure into a pdf page\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Virtulenv_Python_3",
   "language": "python",
   "name": "virtulenv_python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
